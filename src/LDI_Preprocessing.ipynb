{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import argparse\n",
    "import glob\n",
    "import os\n",
    "from functools import partial\n",
    "import vispy\n",
    "import scipy.misc as misc\n",
    "from tqdm import tqdm\n",
    "import time\n",
    "import sys\n",
    "from utils import get_MiDaS_samples, read_MiDaS_depth\n",
    "import torch\n",
    "import cv2\n",
    "from skimage.transform import resize\n",
    "import imageio\n",
    "import copy\n",
    "from MiDaS.monodepth_net import MonoDepthNet\n",
    "import MiDaS.MiDaS_utils as MiDaS_utils\n",
    "from bilateral_filtering import sparse_bilateral_filtering\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Config\n",
    "config is a dictionary which contains model parameters, which have been fine tuned to get optimal results."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "config = {\"depth_edge_model_ckpt\": \"checkpoints/edge-model.pth\",\n",
    "          \"depth_feat_model_ckpt\": \"checkpoints/depth-model.pth\",\n",
    "          \"rgb_feat_model_ckpt\": \"checkpoints/color-model.pth\",\n",
    "          \"MiDaS_model_ckpt\": \"MiDaS/model.pt\",\n",
    "          \"fps\": 40,\n",
    "          \"num_frames\": 240,\n",
    "          \"x_shift_range\": [0.00, 0.00, -0.02, -0.02],\n",
    "          \"y_shift_range\": [0.00, 0.00, -0.02, -0.00],\n",
    "          \"z_shift_range\": [-0.05, -0.05, -0.07, -0.07],\n",
    "          \"traj_types\": ['double-straight-line', 'double-straight-line', 'circle', 'circle'],\n",
    "          \"video_postfix\": ['dolly-zoom-in', 'zoom-in', 'circle', 'swing'],\n",
    "          \"specific\": '',\n",
    "          \"longer_side_len\": 960,\n",
    "          \"src_folder\": \"../images\",\n",
    "          \"depth_folder\": \"../depth\",\n",
    "          \"mesh_folder\": \"../mesh\",\n",
    "          \"video_folder\": \"../video\",\n",
    "          \"output_folder\": \"../outputs\",\n",
    "          \"load_ply\": False,\n",
    "          \"save_ply\": True,\n",
    "          \"inference_video\": True,\n",
    "          \"gpu_ids\": 0,\n",
    "          \"offscreen_rendering\": False,\n",
    "          \"img_format\": '.jpg',\n",
    "          \"depth_format\": '.npy',\n",
    "          \"require_midas\": True,\n",
    "          \"depth_threshold\": 0.04,\n",
    "          \"ext_edge_threshold\": 0.002,\n",
    "          \"sparse_iter\": 5,\n",
    "          \"filter_size\": [7, 7, 5, 5, 5],\n",
    "          \"sigma_s\": 4.0,\n",
    "          \"sigma_r\": 0.5,\n",
    "          \"redundant_number\": 12,\n",
    "          \"background_thickness\": 70,\n",
    "          \"context_thickness\": 140,\n",
    "          \"background_thickness_2\": 70,\n",
    "          \"context_thickness_2\": 70,\n",
    "          \"discount_factor\": 1.00,\n",
    "          \"log_depth\": True,\n",
    "          \"largest_size\": 512,\n",
    "          \"depth_edge_dilate\": 10,\n",
    "          \"depth_edge_dilate_2\": 5,\n",
    "          \"extrapolate_border\": True,\n",
    "          \"extrapolation_thickness\": 60,\n",
    "          \"repeat_inpaint_edge\": True,\n",
    "          \"crop_border\": [0.03, 0.03, 0.05, 0.03],\n",
    "          \"anti_flickering\": True,\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# run_depth\n",
    "run_depth takes in the image, and predicts the depth of each point, using MiDaS library."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_depth(img_names, input_path, output_path, model_path, Net, utils, target_w=None):\n",
    "    device = torch.device(\"cpu\")\n",
    "    model = Net(model_path)\n",
    "    model.to(device)\n",
    "    model.eval()\n",
    "    num_images = len(img_names)\n",
    "    os.makedirs(output_path, exist_ok=True)\n",
    "\n",
    "    for ind, img_name in enumerate(img_names):\n",
    "        print(\"  processing {} ({}/{})\".format(img_name, ind + 1, num_images))\n",
    "        img = utils.read_image(img_name)\n",
    "        w = img.shape[1]\n",
    "        scale = 640. / max(img.shape[0], img.shape[1])\n",
    "        target_height, target_width = int(round(img.shape[0] * scale)), int(round(img.shape[1] * scale))\n",
    "        img_input = utils.resize_image(img)\n",
    "        img_input = img_input.to(device)\n",
    "\n",
    "        with torch.no_grad():\n",
    "            out = model.forward(img_input)\n",
    "        \n",
    "        depth = utils.resize_depth(out, target_width, target_height)\n",
    "        img = cv2.resize((img * 255).astype(np.uint8), (target_width, target_height), interpolation=cv2.INTER_AREA)\n",
    "\n",
    "        filename = os.path.join(\n",
    "            output_path, os.path.splitext(os.path.basename(img_name))[0]\n",
    "        )\n",
    "        np.save(filename + '.npy', depth)\n",
    "        utils.write_depth(filename, depth, bits=2)\n",
    "\n",
    "    print(\"Finished run depth.\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# read_MiDaS_depth\n",
    "read_MiDaS_depth takes in the depth values, smoothens the depth gradient, and takes its inverse. This ensures that the foreground is one, and background contains all other things which are in near vicinity, or far away."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_MiDaS_depth(disp_fi, disp_rescale=10., h=None, w=None):\n",
    "    if 'npy' in os.path.splitext(disp_fi)[-1]:\n",
    "        disp = np.load(disp_fi)\n",
    "    else:\n",
    "        disp = imageio.imread(disp_fi).astype(np.float32)\n",
    "    disp = disp - disp.min()\n",
    "    disp = cv2.blur(disp / disp.max(), ksize=(3, 3)) * disp.max()\n",
    "    disp = (disp / disp.max()) * disp_rescale\n",
    "    if h is not None and w is not None:\n",
    "        disp = resize(disp / disp.max(), (h, w), order=1) * disp.max()\n",
    "    depth = 1. / np.maximum(disp, 0.05)\n",
    "\n",
    "    return depth"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Depth Computation and Bilateral Filtering\n",
    "We have looped for each image. For each image, the depth map has been computed and smoothened. Then, bilateral median filter is used to sharpen the depth map, and discontinuity map is computed, separating the foreground from the background. Output images are stored, for further use."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  0%|          | 0/3 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running depth extraction on image ../image/tiger.jpg\n",
      "  processing ../image/tiger.jpg (1/1)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "  0%|          | 0/5 [00:00<?, ?it/s]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finished run depth.\n",
      "Starting Sparse Bilateral Filtering\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      " 20%|██        | 1/5 [00:05<00:22,  5.55s/it]\u001b[A\n",
      " 40%|████      | 2/5 [00:10<00:16,  5.37s/it]\u001b[A\n",
      " 60%|██████    | 3/5 [00:14<00:09,  4.96s/it]\u001b[A\n",
      " 80%|████████  | 4/5 [00:18<00:04,  4.70s/it]\u001b[A\n",
      "100%|██████████| 5/5 [00:22<00:00,  4.49s/it]\u001b[A\n",
      " 33%|███▎      | 1/3 [00:24<00:48, 24.50s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Written output as tiger.jpg\n",
      "Running depth extraction on image ../image/moon.jpg\n",
      "  processing ../image/moon.jpg (1/1)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "  0%|          | 0/5 [00:00<?, ?it/s]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finished run depth.\n",
      "Starting Sparse Bilateral Filtering\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      " 20%|██        | 1/5 [00:05<00:21,  5.45s/it]\u001b[A\n",
      " 40%|████      | 2/5 [00:10<00:16,  5.42s/it]\u001b[A\n",
      " 60%|██████    | 3/5 [00:15<00:10,  5.22s/it]\u001b[A\n",
      " 80%|████████  | 4/5 [00:20<00:05,  5.03s/it]\u001b[A\n",
      "100%|██████████| 5/5 [00:24<00:00,  4.94s/it]\u001b[A\n",
      " 67%|██████▋   | 2/3 [00:51<00:25, 25.34s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Written output as moon.jpg\n",
      "Running depth extraction on image ../image/ball.jpg\n",
      "  processing ../image/ball.jpg (1/1)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "  0%|          | 0/5 [00:00<?, ?it/s]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finished run depth.\n",
      "Starting Sparse Bilateral Filtering\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      " 20%|██        | 1/5 [00:03<00:15,  3.98s/it]\u001b[A\n",
      " 40%|████      | 2/5 [00:07<00:11,  3.92s/it]\u001b[A\n",
      " 60%|██████    | 3/5 [00:10<00:07,  3.69s/it]\u001b[A\n",
      " 80%|████████  | 4/5 [00:13<00:03,  3.51s/it]\u001b[A\n",
      "100%|██████████| 5/5 [00:17<00:00,  3.41s/it]\u001b[A\n",
      "100%|██████████| 3/3 [01:10<00:00, 23.59s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Written output as ball.jpg\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "sample_list = get_MiDaS_samples(config['src_folder'], config['depth_folder'], config, config['specific'])\n",
    "for idx in tqdm(range(len(sample_list))):\n",
    "    depth = None\n",
    "    sample = sample_list[idx]\n",
    "    image = imageio.imread(sample['ref_img_fi'])\n",
    "    print(\"Running depth extraction on image\", sample['ref_img_fi'])\n",
    "    run_depth([sample['ref_img_fi']], config['src_folder'], config['depth_folder'],\n",
    "              config['MiDaS_model_ckpt'], MonoDepthNet, MiDaS_utils, target_w=640)\n",
    "    config['output_h'], config['output_w'] = np.load(sample['depth_fi']).shape[:2]\n",
    "    frac = config['longer_side_len'] / max(config['output_h'], config['output_w'])\n",
    "    config['output_h'], config['output_w'] = int(config['output_h'] * frac), int(config['output_w'] * frac)\n",
    "    config['original_h'], config['original_w'] = config['output_h'], config['output_w']\n",
    "    if image.ndim == 2:\n",
    "        image = image[..., None].repeat(3, -1)\n",
    "    if np.sum(np.abs(image[..., 0] - image[..., 1])) == 0 and np.sum(np.abs(image[..., 1] - image[..., 2])) == 0:\n",
    "        config['gray_image'] = True\n",
    "    else:\n",
    "        config['gray_image'] = False\n",
    "    image = cv2.resize(image, (config['output_w'], config['output_h']), interpolation=cv2.INTER_AREA)\n",
    "    depth = read_MiDaS_depth(sample['depth_fi'], 3.0, config['output_h'], config['output_w'])\n",
    "    mean_loc_depth = depth[depth.shape[0]//2, depth.shape[1]//2]\n",
    "    vis_photos, vis_depths = sparse_bilateral_filtering(depth.copy(), image.copy(), config, num_iter=config['sparse_iter'], spdb=False)\n",
    "    depth = vis_depths[-1]\n",
    "    img = vis_photos[-1]\n",
    "    img2 = np.uint8(img)\n",
    "    img3 = cv2.cvtColor(img2, cv2.COLOR_BGR2RGB)\n",
    "    cv2.imwrite(config[\"output_folder\"] + \"/\" + sample[\"src_pair_name\"] + \".jpg\", img3)\n",
    "    print(\"Written output as \" + sample[\"src_pair_name\"] + \".jpg\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
